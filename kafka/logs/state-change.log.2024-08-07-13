[2024-08-07 13:36:20,979] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 13:36:20,982] INFO [Broker id=1] Creating new partition _schemas-0 with topic id mRO6kz7iT1-IL2Vp3Vk_pg. (state.change.logger)
[2024-08-07 13:36:21,000] INFO [Broker id=1] Leader _schemas-0 with topic id Some(mRO6kz7iT1-IL2Vp3Vk_pg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,236] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2024-08-07 13:36:21,237] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,241] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,242] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,245] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,246] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,250] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,252] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,255] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,258] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,262] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,263] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,267] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,268] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,271] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,272] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,276] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,277] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,280] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,281] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,284] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,285] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,289] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,291] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,295] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,296] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,299] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,300] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,304] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,305] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,310] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,311] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,316] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,318] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,322] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,324] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,328] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,329] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,332] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,334] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,336] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,337] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,340] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,341] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,345] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,347] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,349] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,351] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,354] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,355] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,358] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,360] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,363] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,364] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,367] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,369] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:21,372] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(w6fo1JXGTwy-50whUX37ow) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 13:36:21,373] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id w6fo1JXGTwy-50whUX37ow. (state.change.logger)
[2024-08-07 13:36:52,959] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 13:36:52,959] INFO [Broker id=1] Creating new partition _confluent-ksql-default__command_topic-0 with topic id 5B70kXgZSrefNim1hy0CTg. (state.change.logger)
[2024-08-07 13:36:53,102] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 13:36:53,102] INFO [Broker id=1] Creating new partition default_ksql_processing_log-0 with topic id UwfMmGduS1u7DxokCmZ20Q. (state.change.logger)
[2024-08-07 13:37:43,802] INFO [Broker id=1] Transitioning 25 partition(s) to local leaders. (state.change.logger)
[2024-08-07 13:37:43,803] INFO [Broker id=1] Creating new partition _kafka-connect-offsets-5 with topic id 6rM8WWhjTwC2cLdnkKqqqg. (state.change.logger)
[2024-08-07 13:39:20,710] INFO [Broker id=1] Transitioning 78 partition(s) to local followers. (state.change.logger)
[2024-08-07 13:39:20,710] INFO [Broker id=1] Follower __consumer_offsets-13 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:20,843] ERROR [Broker id=1] Unable to start fetching default_ksql_processing_log-0 with topic ID UwfMmGduS1u7DxokCmZ20Q due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-07 13:39:20,843] INFO [Broker id=1] Follower __consumer_offsets-46 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:20,843] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-7 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:20,972] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-7 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:20,972] INFO [Broker id=1] Follower __consumer_offsets-9 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:20,972] INFO [Broker id=1] Follower __consumer_offsets-42 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:20,972] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-3 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,107] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-3 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,107] INFO [Broker id=1] Follower __consumer_offsets-21 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,107] INFO [Broker id=1] Follower __consumer_offsets-17 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,107] INFO [Broker id=1] Follower __consumer_offsets-30 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,107] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-23 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,225] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-23 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,227] INFO [Broker id=1] Follower __consumer_offsets-26 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,227] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-19 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,355] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-19 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,355] INFO [Broker id=1] Follower __consumer_offsets-5 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,355] INFO [Broker id=1] Follower __consumer_offsets-38 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,355] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-15 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,490] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-15 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,490] INFO [Broker id=1] Follower __consumer_offsets-1 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,490] INFO [Broker id=1] Follower __consumer_offsets-34 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,490] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-11 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,624] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-11 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,624] INFO [Broker id=1] Follower __consumer_offsets-16 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,624] INFO [Broker id=1] Follower _schemas-0 starts at leader epoch 1 from offset 2 with partition epoch 1 and high watermark 2. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,624] INFO [Broker id=1] Follower __consumer_offsets-45 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,624] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-8 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,766] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-8 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,766] INFO [Broker id=1] Follower __consumer_offsets-12 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,766] INFO [Broker id=1] Follower __consumer_offsets-41 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,766] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-4 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:21,908] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-4 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:21,908] INFO [Broker id=1] Follower __consumer_offsets-24 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:21,908] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-0 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,034] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-0 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,034] INFO [Broker id=1] Follower __consumer_offsets-20 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,034] INFO [Broker id=1] Follower __consumer_offsets-49 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,034] INFO [Broker id=1] Follower __consumer_offsets-0 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,034] INFO [Broker id=1] Follower __consumer_offsets-29 starts at leader epoch 1 from offset 1 with partition epoch 1 and high watermark 1. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,034] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-24 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,174] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-24 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,174] INFO [Broker id=1] Follower __consumer_offsets-25 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,174] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-20 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,299] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-20 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,299] INFO [Broker id=1] Follower __consumer_offsets-8 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,299] INFO [Broker id=1] Follower __consumer_offsets-37 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,299] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-16 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,441] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-16 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,441] INFO [Broker id=1] Follower __consumer_offsets-4 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,441] INFO [Broker id=1] Follower __consumer_offsets-33 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,441] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-12 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,598] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-12 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,598] INFO [Broker id=1] Follower __consumer_offsets-15 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,598] INFO [Broker id=1] Follower __consumer_offsets-48 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 13:39:22,723] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-5 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-07 13:39:22,848] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-11 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-07 13:39:22,848] ERROR [Broker id=1] Expected partition __consumer_offsets-44 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:22,987] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-44 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:22,987] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-1 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,118] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-1 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,118] ERROR [Broker id=1] Expected partition __consumer_offsets-23 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,240] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-23 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,240] ERROR [Broker id=1] Expected partition __consumer_offsets-19 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,367] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-19 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,367] ERROR [Broker id=1] Expected partition __consumer_offsets-32 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,509] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-32 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,509] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-21 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,651] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-21 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,651] ERROR [Broker id=1] Expected partition __consumer_offsets-28 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,772] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-28 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,772] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-17 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:23,889] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-17 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:23,889] ERROR [Broker id=1] Expected partition __consumer_offsets-7 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,018] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-7 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,018] ERROR [Broker id=1] Expected partition __consumer_offsets-40 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,145] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-40 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,145] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-13 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,275] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-13 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,276] ERROR [Broker id=1] Expected partition __consumer_offsets-3 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,400] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-3 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,400] ERROR [Broker id=1] Expected partition __consumer_offsets-36 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,525] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-36 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,525] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-9 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,650] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-9 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,650] ERROR [Broker id=1] Expected partition __consumer_offsets-47 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,775] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-47 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:24,776] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-6 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:24,908] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-6 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,041] ERROR [Broker id=1] Unable to start fetching _confluent-ksql-default__command_topic-0 with topic ID 5B70kXgZSrefNim1hy0CTg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-07 13:39:25,042] ERROR [Broker id=1] Expected partition __consumer_offsets-14 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,174] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-14 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,174] ERROR [Broker id=1] Expected partition __consumer_offsets-43 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,294] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-43 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,294] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-2 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,409] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-2 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,409] ERROR [Broker id=1] Expected partition __consumer_offsets-10 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,547] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-10 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,547] ERROR [Broker id=1] Expected partition __consumer_offsets-22 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,686] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-22 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,686] ERROR [Broker id=1] Expected partition __consumer_offsets-18 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,811] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-18 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,811] ERROR [Broker id=1] Expected partition __consumer_offsets-31 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:25,952] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-31 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:25,952] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-22 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,095] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-22 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,095] ERROR [Broker id=1] Expected partition __consumer_offsets-27 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,232] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-27 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,232] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-18 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,360] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-18 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,360] ERROR [Broker id=1] Expected partition __consumer_offsets-39 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,487] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-39 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,487] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-14 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,614] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-14 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,614] ERROR [Broker id=1] Expected partition __consumer_offsets-6 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,741] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-6 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,741] ERROR [Broker id=1] Expected partition __consumer_offsets-35 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,870] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-35 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,870] ERROR [Broker id=1] Expected partition _kafka-connect-offsets-10 with topic id 6rM8WWhjTwC2cLdnkKqqqg to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:26,993] ERROR [Broker id=1] Unable to start fetching _kafka-connect-offsets-10 with topic ID 6rM8WWhjTwC2cLdnkKqqqg due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:26,994] ERROR [Broker id=1] Expected partition __consumer_offsets-2 with topic id w6fo1JXGTwy-50whUX37ow to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 13:39:27,133] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-2 with topic ID w6fo1JXGTwy-50whUX37ow due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-07 13:39:27,140] INFO [Broker id=1] Stopped fetchers as part of controlled shutdown for 29 partitions (state.change.logger)
