[2024-08-06 14:20:12,304] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:20:12,313] INFO [Broker id=1] Creating new partition _schemas-0 with topic id 88MJdgETSgye3UBZ_Y7E1g. (state.change.logger)
[2024-08-06 14:20:12,367] INFO [Broker id=1] Leader _schemas-0 with topic id Some(88MJdgETSgye3UBZ_Y7E1g) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,611] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:20:12,611] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,611] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,628] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,639] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,642] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,654] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,657] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,667] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,670] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,679] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,685] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,697] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,700] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,710] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,713] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,715] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,726] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,737] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,740] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,750] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,753] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,763] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,765] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,775] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,777] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,777] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,777] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,799] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,802] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,813] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,814] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,821] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,827] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,828] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,828] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,851] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,854] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,864] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,866] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,876] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,878] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,878] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,878] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,902] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,905] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,914] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,916] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,926] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,927] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,927] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,927] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,953] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,955] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,964] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,967] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:12,976] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(peK7XI5sRpSmx_dEBuia1Q) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:20:12,978] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id peK7XI5sRpSmx_dEBuia1Q. (state.change.logger)
[2024-08-06 14:20:37,692] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:20:37,693] INFO [Broker id=1] Creating new partition _confluent-ksql-default__command_topic-0 with topic id 1X5Iy9jOTpy4y7dRRELkZA. (state.change.logger)
[2024-08-06 14:20:37,829] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:20:37,829] INFO [Broker id=1] Creating new partition default_ksql_processing_log-0 with topic id 0esZ9w9GSK2DHRYkbI5FGA. (state.change.logger)
[2024-08-06 14:27:46,584] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:27:46,588] INFO [Broker id=1] Creating new partition _schemas-0 with topic id 5IsZBwIsSiCKvWx-eskNmg. (state.change.logger)
[2024-08-06 14:27:46,604] INFO [Broker id=1] Leader _schemas-0 with topic id Some(5IsZBwIsSiCKvWx-eskNmg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,029] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:27:47,030] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,036] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,037] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,042] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,043] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,047] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,048] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,053] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,054] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,058] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,059] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,064] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,065] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,070] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,071] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,075] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,076] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,080] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,080] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,087] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,088] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,092] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,095] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,100] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,101] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,105] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,106] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,110] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,111] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,117] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,118] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,122] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,128] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,133] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,134] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,139] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,140] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,144] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,146] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,149] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,149] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,152] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,156] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,160] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,161] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,165] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,168] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,171] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,172] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,176] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,178] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,182] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,184] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,188] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,189] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:27:47,193] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(uHVn0IXwSIWt5YsWijwMHw) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:27:47,195] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id uHVn0IXwSIWt5YsWijwMHw. (state.change.logger)
[2024-08-06 14:28:02,690] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:28:02,690] INFO [Broker id=1] Creating new partition _confluent-ksql-default__command_topic-0 with topic id fM93RnAHR5OhnaqG47wXyA. (state.change.logger)
[2024-08-06 14:28:02,854] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:28:02,854] INFO [Broker id=1] Creating new partition default_ksql_processing_log-0 with topic id BHP4h2rdQ6OyaIBUQAIkfQ. (state.change.logger)
[2024-08-06 14:32:29,113] INFO [Broker id=1] Transitioning 53 partition(s) to local followers. (state.change.logger)
[2024-08-06 14:32:29,113] INFO [Broker id=1] Follower __consumer_offsets-13 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,238] ERROR [Broker id=1] Unable to start fetching default_ksql_processing_log-0 with topic ID BHP4h2rdQ6OyaIBUQAIkfQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-46 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-9 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-42 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-21 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-17 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-30 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-26 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-5 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-38 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-1 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-34 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower _schemas-0 starts at leader epoch 1 from offset 1 with partition epoch 1 and high watermark 1. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-16 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-45 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-12 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-41 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-24 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-20 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-49 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-0 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-29 starts at leader epoch 1 from offset 1 with partition epoch 1 and high watermark 1. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-25 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-8 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-37 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-4 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-33 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-15 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,239] INFO [Broker id=1] Follower __consumer_offsets-48 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-06 14:32:29,363] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-11 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-06 14:32:29,365] ERROR [Broker id=1] Expected partition __consumer_offsets-44 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:29,494] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-44 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:29,494] ERROR [Broker id=1] Expected partition __consumer_offsets-23 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:29,622] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-23 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:29,622] ERROR [Broker id=1] Expected partition __consumer_offsets-19 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:29,751] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-19 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:29,752] ERROR [Broker id=1] Expected partition __consumer_offsets-32 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:29,885] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-32 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:29,885] ERROR [Broker id=1] Expected partition __consumer_offsets-28 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:29,997] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-28 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:29,997] ERROR [Broker id=1] Expected partition __consumer_offsets-7 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,125] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-7 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,125] ERROR [Broker id=1] Expected partition __consumer_offsets-40 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,246] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-40 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,248] ERROR [Broker id=1] Expected partition __consumer_offsets-3 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,391] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-3 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,391] ERROR [Broker id=1] Expected partition __consumer_offsets-36 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,507] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-36 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,507] ERROR [Broker id=1] Expected partition __consumer_offsets-47 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,635] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-47 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,635] ERROR [Broker id=1] Expected partition __consumer_offsets-14 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:30,778] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-14 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:30,920] ERROR [Broker id=1] Unable to start fetching _confluent-ksql-default__command_topic-0 with topic ID fM93RnAHR5OhnaqG47wXyA due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.sanityCheck(LogSegment.java:186)
	at kafka.log.LogLoader.$anonfun$loadSegmentFiles$3(LogLoader.scala:327)
	at scala.collection.TraversableLike$WithFilter.$anonfun$foreach$1(TraversableLike.scala:985)
	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)
	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:984)
	at kafka.log.LogLoader.loadSegmentFiles(LogLoader.scala:304)
	at kafka.log.LogLoader.$anonfun$load$10(LogLoader.scala:150)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 54 more
[2024-08-06 14:32:30,920] ERROR [Broker id=1] Expected partition __consumer_offsets-43 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,055] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-43 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,055] ERROR [Broker id=1] Expected partition __consumer_offsets-10 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,198] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-10 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,198] ERROR [Broker id=1] Expected partition __consumer_offsets-22 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,324] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-22 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,324] ERROR [Broker id=1] Expected partition __consumer_offsets-18 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,451] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-18 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,451] ERROR [Broker id=1] Expected partition __consumer_offsets-31 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,589] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-31 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,589] ERROR [Broker id=1] Expected partition __consumer_offsets-27 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,715] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-27 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,717] ERROR [Broker id=1] Expected partition __consumer_offsets-39 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:31,858] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-39 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:31,858] ERROR [Broker id=1] Expected partition __consumer_offsets-6 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:32,001] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-6 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:32,001] ERROR [Broker id=1] Expected partition __consumer_offsets-35 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:32,141] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-35 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:32,141] ERROR [Broker id=1] Expected partition __consumer_offsets-2 with topic id uHVn0IXwSIWt5YsWijwMHw to exist, but it was missing. Creating... (state.change.logger)
[2024-08-06 14:32:32,283] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-2 with topic ID uHVn0IXwSIWt5YsWijwMHw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.OffsetIndex.<init>(OffsetIndex.java:70)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:240)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.offsetIndex(LogSegment.java:138)
	at org.apache.kafka.storage.internals.log.LogSegment.readNextOffset(LogSegment.java:611)
	at kafka.log.LogLoader.$anonfun$recoverLog$7(LogLoader.scala:474)
	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogLoader.recoverLog(LogLoader.scala:474)
	at kafka.log.LogLoader.$anonfun$load$11(LogLoader.scala:155)
	at kafka.log.LogLoader.load(LogLoader.scala:272)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 51 more
[2024-08-06 14:32:32,285] INFO [Broker id=1] Stopped fetchers as part of controlled shutdown for 29 partitions (state.change.logger)
[2024-08-06 14:34:22,561] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:34:22,564] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,582] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,585] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,589] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,590] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,595] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,598] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,602] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,604] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,608] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,610] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,614] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,615] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,620] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,622] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,626] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,628] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,632] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,634] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,639] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,640] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,645] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,647] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,651] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,652] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,656] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,658] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,662] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,664] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,668] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,670] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,674] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,675] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,680] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,683] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,687] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,689] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,694] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,695] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,699] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,701] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,705] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,706] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,711] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,712] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,717] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,718] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,722] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,723] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,728] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,730] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,735] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,737] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,741] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,742] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,751] INFO [Broker id=1] Leader __consumer_offsets-48 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,753] INFO [Broker id=1] Creating new partition __consumer_offsets-11 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,795] INFO [Broker id=1] Leader __consumer_offsets-11 with topic id Some(Og9HAoUYQ9aBuUDdTp_zFg) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-06 14:34:22,796] INFO [Broker id=1] Creating new partition __consumer_offsets-44 with topic id Og9HAoUYQ9aBuUDdTp_zFg. (state.change.logger)
[2024-08-06 14:34:22,962] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:34:22,962] INFO [Broker id=1] Creating new partition _schemas-0 with topic id ei3-DQTTR-6wCrAWPDpDzA. (state.change.logger)
[2024-08-06 14:35:05,563] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:35:05,563] INFO [Broker id=1] Creating new partition _confluent-ksql-default__command_topic-0 with topic id NAVO0e_FSFCjR4vCRlJAxg. (state.change.logger)
[2024-08-06 14:35:05,691] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-06 14:35:05,691] INFO [Broker id=1] Creating new partition default_ksql_processing_log-0 with topic id JMo_UmNfRh22lPRPfQuO_g. (state.change.logger)
