[2024-08-07 14:04:50,259] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 14:04:50,261] INFO [Broker id=1] Creating new partition _schemas-0 with topic id 4-E9J5FvQ-2LU9kgpKrBTA. (state.change.logger)
[2024-08-07 14:04:50,279] INFO [Broker id=1] Leader _schemas-0 with topic id Some(4-E9J5FvQ-2LU9kgpKrBTA) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,429] INFO [Broker id=1] Transitioning 50 partition(s) to local leaders. (state.change.logger)
[2024-08-07 14:04:50,431] INFO [Broker id=1] Creating new partition __consumer_offsets-13 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,437] INFO [Broker id=1] Leader __consumer_offsets-13 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,438] INFO [Broker id=1] Creating new partition __consumer_offsets-46 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,442] INFO [Broker id=1] Leader __consumer_offsets-46 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,444] INFO [Broker id=1] Creating new partition __consumer_offsets-9 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,448] INFO [Broker id=1] Leader __consumer_offsets-9 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,450] INFO [Broker id=1] Creating new partition __consumer_offsets-42 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,453] INFO [Broker id=1] Leader __consumer_offsets-42 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,454] INFO [Broker id=1] Creating new partition __consumer_offsets-21 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,458] INFO [Broker id=1] Leader __consumer_offsets-21 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,460] INFO [Broker id=1] Creating new partition __consumer_offsets-17 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,464] INFO [Broker id=1] Leader __consumer_offsets-17 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,464] INFO [Broker id=1] Creating new partition __consumer_offsets-30 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,469] INFO [Broker id=1] Leader __consumer_offsets-30 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,470] INFO [Broker id=1] Creating new partition __consumer_offsets-26 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,474] INFO [Broker id=1] Leader __consumer_offsets-26 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,475] INFO [Broker id=1] Creating new partition __consumer_offsets-5 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,479] INFO [Broker id=1] Leader __consumer_offsets-5 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,480] INFO [Broker id=1] Creating new partition __consumer_offsets-38 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,484] INFO [Broker id=1] Leader __consumer_offsets-38 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,484] INFO [Broker id=1] Creating new partition __consumer_offsets-1 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,484] INFO [Broker id=1] Leader __consumer_offsets-1 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,484] INFO [Broker id=1] Creating new partition __consumer_offsets-34 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,494] INFO [Broker id=1] Leader __consumer_offsets-34 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,495] INFO [Broker id=1] Creating new partition __consumer_offsets-16 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,500] INFO [Broker id=1] Leader __consumer_offsets-16 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,501] INFO [Broker id=1] Creating new partition __consumer_offsets-45 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,505] INFO [Broker id=1] Leader __consumer_offsets-45 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,506] INFO [Broker id=1] Creating new partition __consumer_offsets-12 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,510] INFO [Broker id=1] Leader __consumer_offsets-12 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,511] INFO [Broker id=1] Creating new partition __consumer_offsets-41 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,516] INFO [Broker id=1] Leader __consumer_offsets-41 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,517] INFO [Broker id=1] Creating new partition __consumer_offsets-24 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,521] INFO [Broker id=1] Leader __consumer_offsets-24 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,523] INFO [Broker id=1] Creating new partition __consumer_offsets-20 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,528] INFO [Broker id=1] Leader __consumer_offsets-20 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,530] INFO [Broker id=1] Creating new partition __consumer_offsets-49 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,535] INFO [Broker id=1] Leader __consumer_offsets-49 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,536] INFO [Broker id=1] Creating new partition __consumer_offsets-0 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,540] INFO [Broker id=1] Leader __consumer_offsets-0 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,542] INFO [Broker id=1] Creating new partition __consumer_offsets-29 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,546] INFO [Broker id=1] Leader __consumer_offsets-29 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,547] INFO [Broker id=1] Creating new partition __consumer_offsets-25 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,551] INFO [Broker id=1] Leader __consumer_offsets-25 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,552] INFO [Broker id=1] Creating new partition __consumer_offsets-8 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,558] INFO [Broker id=1] Leader __consumer_offsets-8 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,559] INFO [Broker id=1] Creating new partition __consumer_offsets-37 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,564] INFO [Broker id=1] Leader __consumer_offsets-37 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,569] INFO [Broker id=1] Creating new partition __consumer_offsets-4 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,574] INFO [Broker id=1] Leader __consumer_offsets-4 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,575] INFO [Broker id=1] Creating new partition __consumer_offsets-33 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,579] INFO [Broker id=1] Leader __consumer_offsets-33 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,580] INFO [Broker id=1] Creating new partition __consumer_offsets-15 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:04:50,584] INFO [Broker id=1] Leader __consumer_offsets-15 with topic id Some(8vJTjav0RW6KZwHUDIIEzQ) starts at leader epoch 0 from offset 0 with partition epoch 0, high watermark 0, ISR [1], adding replicas [] and removing replicas [] . Previous leader None and previous leader epoch was -1. (state.change.logger)
[2024-08-07 14:04:50,585] INFO [Broker id=1] Creating new partition __consumer_offsets-48 with topic id 8vJTjav0RW6KZwHUDIIEzQ. (state.change.logger)
[2024-08-07 14:05:46,110] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 14:05:46,110] INFO [Broker id=1] Creating new partition _confluent-ksql-default__command_topic-0 with topic id Ezqae90aT_KVv3aXhdL7yw. (state.change.logger)
[2024-08-07 14:05:46,365] INFO [Broker id=1] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-08-07 14:05:46,366] INFO [Broker id=1] Creating new partition default_ksql_processing_log-0 with topic id a3lZltN0Q9iDsxrhoqTKCA. (state.change.logger)
[2024-08-07 14:14:02,129] INFO [Broker id=1] Transitioning 53 partition(s) to local followers. (state.change.logger)
[2024-08-07 14:14:02,130] INFO [Broker id=1] Follower __consumer_offsets-13 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] ERROR [Broker id=1] Unable to start fetching default_ksql_processing_log-0 with topic ID a3lZltN0Q9iDsxrhoqTKCA due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-46 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-9 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-42 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-21 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-17 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-30 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-26 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-5 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-38 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-1 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-34 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower _schemas-0 starts at leader epoch 1 from offset 1 with partition epoch 1 and high watermark 1. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-16 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-45 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-12 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-41 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-24 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-20 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-49 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-0 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-29 starts at leader epoch 1 from offset 1 with partition epoch 1 and high watermark 1. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-25 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-8 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-37 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-4 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-33 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,392] INFO [Broker id=1] Follower __consumer_offsets-15 starts at leader epoch 1 from offset 0 with partition epoch 1 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 1. (state.change.logger)
[2024-08-07 14:14:02,637] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-48 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:02,638] ERROR [Broker id=1] Expected partition __consumer_offsets-11 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:02,890] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-11 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:02,890] ERROR [Broker id=1] Expected partition __consumer_offsets-44 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:03,155] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-44 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:03,155] ERROR [Broker id=1] Expected partition __consumer_offsets-23 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:03,440] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-23 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:03,440] ERROR [Broker id=1] Expected partition __consumer_offsets-19 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:03,703] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-19 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:03,703] ERROR [Broker id=1] Expected partition __consumer_offsets-32 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:03,971] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-32 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:03,971] ERROR [Broker id=1] Expected partition __consumer_offsets-28 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:04,237] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-28 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:04,237] ERROR [Broker id=1] Expected partition __consumer_offsets-7 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:04,505] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-7 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:04,505] ERROR [Broker id=1] Expected partition __consumer_offsets-40 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:04,754] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-40 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:04,754] ERROR [Broker id=1] Expected partition __consumer_offsets-3 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:05,021] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-3 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:05,021] ERROR [Broker id=1] Expected partition __consumer_offsets-36 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:05,270] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-36 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:05,270] ERROR [Broker id=1] Expected partition __consumer_offsets-47 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:05,523] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-47 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:05,773] ERROR [Broker id=1] Unable to start fetching _confluent-ksql-default__command_topic-0 with topic ID Ezqae90aT_KVv3aXhdL7yw due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:05,773] ERROR [Broker id=1] Expected partition __consumer_offsets-14 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:06,041] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-14 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:06,041] ERROR [Broker id=1] Expected partition __consumer_offsets-43 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:06,306] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-43 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:06,306] ERROR [Broker id=1] Expected partition __consumer_offsets-10 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:06,559] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-10 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:06,559] ERROR [Broker id=1] Expected partition __consumer_offsets-22 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:06,823] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-22 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:06,823] ERROR [Broker id=1] Expected partition __consumer_offsets-18 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:07,076] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-18 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:07,076] ERROR [Broker id=1] Expected partition __consumer_offsets-31 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:07,325] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-31 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:07,325] ERROR [Broker id=1] Expected partition __consumer_offsets-27 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:07,578] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-27 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:07,578] ERROR [Broker id=1] Expected partition __consumer_offsets-39 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:07,858] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-39 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:07,858] ERROR [Broker id=1] Expected partition __consumer_offsets-6 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:08,143] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-6 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:08,143] ERROR [Broker id=1] Expected partition __consumer_offsets-35 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:08,407] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-35 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:08,407] ERROR [Broker id=1] Expected partition __consumer_offsets-2 with topic id 8vJTjav0RW6KZwHUDIIEzQ to exist, but it was missing. Creating... (state.change.logger)
[2024-08-07 14:14:08,691] ERROR [Broker id=1] Unable to start fetching __consumer_offsets-2 with topic ID 8vJTjav0RW6KZwHUDIIEzQ due to IOException (state.change.logger)
java.io.IOException: Map failed
	at sun.nio.ch.FileChannelImpl.map(Unknown Source)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createMappedBuffer(AbstractIndex.java:467)
	at org.apache.kafka.storage.internals.log.AbstractIndex.createAndAssignMmap(AbstractIndex.java:105)
	at org.apache.kafka.storage.internals.log.AbstractIndex.<init>(AbstractIndex.java:83)
	at org.apache.kafka.storage.internals.log.TimeIndex.<init>(TimeIndex.java:65)
	at org.apache.kafka.storage.internals.log.LazyIndex.loadIndex(LazyIndex.java:242)
	at org.apache.kafka.storage.internals.log.LazyIndex.get(LazyIndex.java:179)
	at org.apache.kafka.storage.internals.log.LogSegment.timeIndex(LogSegment.java:146)
	at org.apache.kafka.storage.internals.log.LogSegment.resizeIndexes(LogSegment.java:179)
	at kafka.log.LogLoader.load(LogLoader.scala:158)
	at kafka.log.UnifiedLog$.apply(UnifiedLog.scala:2005)
	at kafka.log.LogManager.$anonfun$getOrCreateLog$1(LogManager.scala:1066)
	at scala.Option.getOrElse(Option.scala:189)
	at kafka.log.LogManager.getOrCreateLog(LogManager.scala:1023)
	at kafka.cluster.Partition.createLog(Partition.scala:480)
	at kafka.cluster.Partition.maybeCreate$1(Partition.scala:454)
	at kafka.cluster.Partition.createLogIfNotExists(Partition.scala:461)
	at kafka.cluster.Partition.createLogInAssignedDirectoryId(Partition.scala:886)
	at kafka.cluster.Partition.$anonfun$makeFollower$1(Partition.scala:848)
	at kafka.cluster.Partition.makeFollower(Partition.scala:819)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$3(ReplicaManager.scala:2939)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2(ReplicaManager.scala:2928)
	at kafka.server.ReplicaManager.$anonfun$applyLocalFollowersDelta$2$adapted(ReplicaManager.scala:2927)
	at kafka.utils.Implicits$MapExtensionMethods$.$anonfun$forKeyValue$1(Implicits.scala:62)
	at scala.collection.compat.MapExtensionMethods$.$anonfun$foreachEntry$1(PackageShared.scala:589)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.compat.MapExtensionMethods$.foreachEntry$extension(PackageShared.scala:589)
	at kafka.server.ReplicaManager.applyLocalFollowersDelta(ReplicaManager.scala:2927)
	at kafka.server.ReplicaManager.applyDelta(ReplicaManager.scala:2862)
	at kafka.server.metadata.BrokerMetadataPublisher.$anonfun$onMetadataUpdate$8(BrokerMetadataPublisher.scala:151)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.metadata.BrokerMetadataPublisher.onMetadataUpdate(BrokerMetadataPublisher.scala:148)
	at org.apache.kafka.image.loader.MetadataLoader.maybePublishMetadata(MetadataLoader.java:341)
	at org.apache.kafka.image.loader.MetadataBatchLoader.applyDeltaAndUpdate(MetadataBatchLoader.java:272)
	at org.apache.kafka.image.loader.MetadataBatchLoader.maybeFlushBatches(MetadataBatchLoader.java:208)
	at org.apache.kafka.image.loader.MetadataLoader.lambda$handleCommit$1(MetadataLoader.java:365)
	at org.apache.kafka.queue.KafkaEventQueue$EventContext.run(KafkaEventQueue.java:127)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.handleEvents(KafkaEventQueue.java:210)
	at org.apache.kafka.queue.KafkaEventQueue$EventHandler.run(KafkaEventQueue.java:181)
	at java.lang.Thread.run(Unknown Source)
Caused by: java.lang.OutOfMemoryError: Map failed
	at sun.nio.ch.FileChannelImpl.map0(Native Method)
	... 46 more
[2024-08-07 14:14:08,691] INFO [Broker id=1] Stopped fetchers as part of controlled shutdown for 28 partitions (state.change.logger)
